from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from typing import Dict, List, Optional


class EmbeddingDatabase:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ —Ä–∞–±–æ—Ç—ã —Å –º–æ–¥–µ–ª—å—é —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.

    –ü–æ–∑–≤–æ–ª—è–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö, –¥–æ–±–∞–≤–ª—è—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑–∞–ø–∏—Å–∏.
    """

    def __init__(self, persist_directory: str, model_name: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.

        :param persist_directory: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö Chroma.
        :param model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ HuggingFace.
        """
        self.embedding_model = HuggingFaceEmbeddings(model_name=model_name)
        self.vector_store = Chroma(persist_directory=persist_directory, embedding_function=self.embedding_model)

    def add_text(self, text: List[str], metadatas: List[Dict[str, str]] = None) -> None:
        """
        –î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏.

        :param text: –¢–µ–∫—Å—Ç –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
        :param metadatas: –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, {"–∫–∞—Ç–µ–≥–æ—Ä–∏—è": "–∑–∞–º–µ—Ç–∫–∏", "–¥–∞—Ç–∞": "04.06.2025"}).
        """
        metadatas = metadatas or []  # –ï—Å–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        self.vector_store.add_texts(texts=text, metadatas=metadatas)  # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
        print(f"‚úÖ –ó–∞–º–µ—Ç–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω—ã")

    def retrieve_relevant_texts(self, query: str, k: int = 3, filter_metadata: Optional[Dict[str, str]] = None) -> List[
        str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º.

        :param query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        :param k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è.
        :param filter_metadata: –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, {"–∫–∞—Ç–µ–≥–æ—Ä–∏—è": "–∑–∞–º–µ—Ç–∫–∏"}).
        :return: –°–ø–∏—Å–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.
        """
        retriever = self.vector_store.as_retriever(search_kwargs={"k": k, "filter": filter_metadata or {}})
        relevant_chunks = retriever.invoke(query)
        return [chunk.page_content for chunk in relevant_chunks]

    from typing import Optional, Dict, List, Any

    def get_notes(self, query_text: Optional[str] = "", k: int = 10,
                  filter_metadata: Optional[Dict[str, str]] = None,
                  get_metadata: bool = False,
                  word_for_search: dict = None) -> List[Dict[str, dict]] or List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–º–µ—Ç–∫–∏, —Ñ–∏–ª—å—Ç—Ä—É—è –∏—Ö –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º –∏/–∏–ª–∏ –Ω–∞—Ö–æ–¥—è –ø–æ—Ö–æ–∂–∏–µ —Ç–µ–∫—Å—Ç—ã –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –∑–∞–º–µ—Ç–æ–∫ –∏ –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã).

        :param query_text: –¢–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø–∏—Å–µ–π (–µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω).
        :param k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
        :param filter_metadata: –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏–§–æ—Ä–º–∞—Ç:
        {"–∫–ª—é—á": {"$eq": –∑–Ω–∞—á–µ–Ω–∏–µ}, "—á–∏—Å–ª–æ–≤–æ–µ_–ø–æ–ª–µ": {"$gte": —á–∏—Å–ª–æ}}
        :param get_metadata: –§–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π, –Ω—É–∂–Ω–æ –ª–∏ –≤–µ—Ä–Ω—É—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.
        :param word_for_search: —Å–ª–æ–≤–æ –∏–ª–∏ —Ñ—Ä–∞–∑–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        :return: –°–ø–∏—Å–æ–∫ [{text: "...", metadata: {...}}] –∏–ª–∏ [str]
        """
        print("–°–µ–π—á–∞—Å –≤ –±–∞–∑–µ", self.vector_store._collection.get())  # –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å—é –±–∞–∑—É

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ª–æ–≤–∞—Ä—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
        if query_text:
            # –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∑–∞–ø–∏—Å–µ–π –ø–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º –∏ –≤–æ–∑–º–æ–∂–Ω–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
            # results = self.vector_store.similarity_search(query=query_text, k=k, filter=filter_metadata)
            print("filter_metadata", filter_metadata)
            results = self.vector_store.similarity_search(query=query_text, k=k, filter=filter_metadata)
            print("results", results)
            if not results:
                return []
            if get_metadata:
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–º–µ—Ç–æ–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{text: "...", metadata: {...}}]
                # –° –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ –±–µ–∑ –Ω–∏—Ö
                return [{"text": doc.page_content, "metadata": doc.metadata} for doc in results]
            return [doc.page_content for doc in results]

        else:
            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
            param = {"where": filter_metadata}
            if word_for_search:
                # –ê–∫—Ç–∏–≤–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –ø–æ —Å–ª–æ–≤—É
                param["where_document"] = word_for_search
            print("filter_metadata", param)
            results = self.vector_store.get(**param)
            print("–†–µ–∑—É–ª—å—Ç–∞—Ç —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ –∑–∞–ø—Ä–æ—Å–∞", results)
            # print(self.vector_store._collection.get(include=["embeddings", "documents", "metadatas"]))  # –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å—é –±–∞–∑—É
            if not results["documents"]:
                return []
            if get_metadata:
                # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–º–µ—Ç–æ–∫ –≤ —Ñ–æ—Ä–º–∞—Ç–µ [{text: "...", metadata: {...}}]
                # –° –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –∏–ª–∏ –±–µ–∑ –Ω–∏—Ö
                return [{"text": doc, "metadata": meta} for doc, meta in
                        zip(results["documents"], results["metadatas"])]
            return [doc for doc in results["documents"]]



    # def get_notes(self, filter_metadata: Optional[Dict[str, str]] = None, get_metadata: bool = False) -> List[Dict[str, Any]]:
    #     """
    #     –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–º–µ—Ç–∫–∏, —Ñ–∏–ª—å—Ç—Ä—É—è –∏—Ö –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º (–µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã).
    #     –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Ç–µ–∫—Å—Ç–∞–º–∏ –∑–∞–º–µ—Ç–æ–∫ –∏ –∏—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ (–µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã).
    #
    #     :param filter_metadata: –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, {"–∫–∞—Ç–µ–≥–æ—Ä–∏—è": "–ø—Ä–æ–µ–∫—Ç"}).
    #     :param get_metadata: –§–ª–∞–≥, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π, –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–ª—É—á–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.
    #     :return: –°–ø–∏—Å–æ–∫ [{text: "...", metadata: {...}}]
    #     """
    #
    #     if filter_metadata:
    #         results = self.vector_store.get(where=filter_metadata)  # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º
    #     else:
    #         results = self.vector_store.get()  # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø–∏—Å–µ–π
    #
    #     documents = results["documents"]
    #     metadatas = results["metadatas"]
    #
    #     # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–º–µ—Ç–æ–∫
    #     if get_metadata:
    #         return [{"text": doc, "metadata": meta} for doc, meta in zip(documents, metadatas)]
    #     return [doc for doc in documents]


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
    PERSIST_DIRECTORY = "./chroma_db"
    MODEL_NAME = "ai-forever/ru-en-RoSBERTa"

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    embedding_db = EmbeddingDatabase(persist_directory=PERSIST_DIRECTORY, model_name=MODEL_NAME)

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–º–µ—Ç–æ–∫ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
    embedding_db.add_text("–ü—Ä–∏–º–µ—Ä –∑–∞–º–µ—Ç–∫–∏ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.", {"–∫–∞—Ç–µ–≥–æ—Ä–∏—è": "–∑–∞–º–µ—Ç–∫–∏", "–¥–∞—Ç–∞": "04.06.2025"})
    embedding_db.add_text("–í–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–µ–∫—Ç–µ.", {"–∫–∞—Ç–µ–≥–æ—Ä–∏—è": "–ø—Ä–æ–µ–∫—Ç", "–¥–∞—Ç–∞": "03.06.2025"})

    # –ó–∞–ø—Ä–æ—Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
    results = embedding_db.retrieve_relevant_texts("—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ")
    print("\nüîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏:")
    for res in results:
        print(f"- {res}")

    # –ó–∞–ø—Ä–æ—Å —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    filtered_results = embedding_db.retrieve_relevant_texts("–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è", filter_metadata={"–∫–∞—Ç–µ–≥–æ—Ä–∏—è": "–ø—Ä–æ–µ–∫—Ç"})
    print("\nüîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–º–µ—Ç–∫–∏ (–∫–∞—Ç–µ–≥–æ—Ä–∏—è: –ø—Ä–æ–µ–∫—Ç):")
    for res in filtered_results:
        print(f"- {res}")
